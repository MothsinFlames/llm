---
---
大模型由于参数量和计算量都非常大，基本不可能通过单卡进行训练。本文对常见的[并行训练](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=%E5%B9%B6%E8%A1%8C%E8%AE%AD%E7%BB%83&zhida_source=entity)中的常见概念和算法进行了总结。

## 0、集体通讯常见术语

**0.1 Reduce**

Reduce 操作，将不同节点上的数据，经过通讯之后，通过函数 f 得到一个新的值。即 $\alpha =f(a,b,c)$。

![|400](https://picx.zhimg.com/v2-6bb4a1fd6919cc0a026b5422d777ac2d_1440w.jpg)

Reduce

**0.2 All-Reduce**

所有的节点都完成上述的 Reduce操作。

![|425](https://picx.zhimg.com/v2-d26bd09695f010330751968432260d7f_1440w.jpg)

All-Reduce

**0.3 Gather**

将不同节点的数据，都通过通讯，传递到同一个节点。

![|500](https://pic1.zhimg.com/v2-8fd20ef33d172775053aba7d80485410_1440w.jpg)

Gather

**0.4 All-Gather**

对所有节点，都采用Gather操作。

![|500](https://pic1.zhimg.com/v2-a8d8a633827b2af5d99089ef3151be82_1440w.jpg)

All-Gather

**0.5 Scatter**

将一个节点的数据，通过通讯，分片到不同的节点上。

![|500](https://pic2.zhimg.com/v2-a80c747f29ef6ac4f6c8e506f7ea9a77_1440w.jpg)

Scatter

## 1、数据并行

[数据并行](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=2&q=%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C&zhida_source=entity)，是指将数据切分，分别在多的模型实例上进行训练的方法。可以分为参数服务器方法（Parameter Server）和 All-Reduce 方法。

### 1.1 参数服务器方法

参数服务器方法中，会有 server 节点和 worker 节点。其中，server 节点负责全部模型参数的维护和梯度更新，worker 节点负责前向计算和反向传播计算梯度。[参数服务器](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=4&q=%E5%8F%82%E6%95%B0%E6%9C%8D%E5%8A%A1%E5%99%A8&zhida_source=entity)的架构图如下所示[\[1\]](#ref_1)：

![|475](https://picx.zhimg.com/v2-be0393089be9c63afaeccc68756f34a3_1440w.jpg)

Scaling Distributed Machine Learning with the Parameter Server

**参数服务器的算法流程：**

1.  从分布式数据加载器中载入数据
2.  worker 节点进行前向计算和反向计算，得到梯度
3.  worker 节点将梯度传给 server 节点
4.  server 节点进行梯度更新
5.  worker 节点从 server 节点拉取新的参数（保证了每个节点拿到的参数都是相同的）

**参数服务器方法的缺点：**

worker节点和 server 节点的负载不均衡

### 1.2 All-Reduce方法

为了实现负载的均衡，可以将梯度同步到每个节点，在每个节点本地进行梯度计算。从而避免了worker节点的空闲浪费。

**All-Reduce方法的算法流程：**

1.  从[分布式数据加载器](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=2&q=%E5%88%86%E5%B8%83%E5%BC%8F%E6%95%B0%E6%8D%AE%E5%8A%A0%E8%BD%BD%E5%99%A8&zhida_source=entity)中载入数据
2.  前向计算和反向计算，得到梯度
3.  梯度进行 All-Reduce 操作
4.  每个节点在本地进行参数更新

**All-Reduce方法的缺点：**

所有的节点都进行了一次优化器的更新，存在冗余。

### 1.3 数据并行提高效率技巧

数据并行可以采用以下方法提升效率[\[2\]](#ref_2)：

**1.3.1 梯度分桶**

梯度分桶是指，在通讯的过程中，可以将要传输的数据，分为不同的大小（桶大小），然后进行传输。每个桶的大小越大，通信操作可能会变得更快，但也需要更多的内存来存储中间结果。合适的桶大小要根据实际情况调整。

![](https://pic3.zhimg.com/v2-3ccc3e87f30860c2b4f2a27f564c9cc8_1440w.jpg)

PyTorch Distributed: Experiences on AcceleratingData Parallel Training

上图是使用32块 GPU分别训练 ResNet 和 BERT 的效果，桶大小为0，意味着每个梯度一旦准备好就会进行通讯。

在 deepspeed 中，可以通过参数 `allgather_bucket_size` 和 `reduce_bucket_size` 等参数来控制分桶的大小。 具体可以参考之前的文章 [deepspeed入门教程 - JOYWIN的文章](https://zhuanlan.zhihu.com/p/630734624)。

**1.3.2 计算与通讯重叠**

有了梯度分桶之后，在同一个桶的梯度计算完成之后，就可以开始进行通讯，而不需要等待所有梯度都计算完成。使用计算和通讯重叠之后，在NCCL后端上，ResNet 和 BERT 分别获得 38.0% 和 35.2% 的加速。 而在 GLOO 后端，增益分别为 26.8% 和 21.5%。

![|575](https://pica.zhimg.com/v2-1b94ad78acc071fc38f23e2403f94018_1440w.jpg)

PyTorch Distributed: Experiences on AcceleratingData Parallel Training

图中，FWD表示前向计算，BWD表示反向计算，COMM为通讯，OPT为参数更新。

在 deepspeed 中，使用 `overlap_comm` 参数对计算和通讯重叠进行控制。

**1.3.3 跳过梯度同步**

通过梯度累加，减少梯度通讯的频次，相当于变相增大[batch size](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=batch+size&zhida_source=entity)。

使用更大的batch size，有2个好处：

-   GPU每次做运算的矩阵变大了，可以更好的使用[单GPU](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=%E5%8D%95GPU&zhida_source=entity)所有的核，单GPU的性能提升，计算变快
-   通讯量没变，计算量增大，计算通讯比变得更好了，对于整体分布式性能更好

但太大的 batch size 也会带来收敛变慢的风险，需要在实际中进行取舍。

![|675](https://pic1.zhimg.com/v2-2091d940908a71facff56708966532aa_1440w.jpg)

PyTorch Distributed: Experiences on AcceleratingData Parallel Training

## 2、ZeRO

数据并行的缺点是，在所有的节点上，都保存了完整的参数、梯度和优化器状态，有较大的冗余。

零冗余优化器 ZeRO（Zero Redundancy Optimizer）是针对以上问题的改进。在[pytorch](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=pytorch&zhida_source=entity) 中，也称为FSDP。

### 2.1 [混合精度训练](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=%E6%B7%B7%E5%90%88%E7%B2%BE%E5%BA%A6%E8%AE%AD%E7%BB%83&zhida_source=entity)中的内存占用

在模型训练中，fp16会比fp32快很多，因此，一般会使用fp16的参数进行模型的前向和后向计算。然而，在进行梯度累加的时候，fp16往往会精度不够，无法满足计算需求。因此，会在反向计算的时候，采用fp32。

假设模型一共有 M 个参数，则fp16的参数和梯度，一共需要 4M bytes，而fp32需要存参数、adam中的[momentum](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=momentum&zhida_source=entity) 和 variances，一共是 12M​ bytes。因此，模型参数、梯度和优化器状态，一共会需要 16M bytes的存储[\[3\]](#ref_3)。

### 2.2 不同 ZeRO stage的对比

ZeRO 的不同 stage，会将不同的数据进行分片。具体而言，stage 1 将优化器状态进行了分片，stage 2 将优化器状态和梯度进行了分片，stage 3 将优化器状态、梯度和参数，均进行了分片。不同stage中，显存占用和通讯的对比如下所示。

![|675](https://pic1.zhimg.com/v2-69f5c220f29bffc90de8262747d64c68_1440w.jpg)

可以看到，随着 ZeRO stage的增加，对于显存的需求越来越小。而 stage 3会比 stage 1 和 2 多出额外 50%的通讯。具体不同ZeRO stage 如何选择，参数如何调整，可以参考之前的文章 [deepspeed入门教程 - JOYWIN的文章](https://zhuanlan.zhihu.com/p/630734624)。

### 2.3 ZeRO-offload

当使用了ZeRO之后，如果还没法将模型在GPU上进行训练，可以考虑使用 offload 到 CPU 的内存上。同时，可以利用部分CPU的算力，以减少通讯。

因此，[ZeRO-offload](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=2&q=ZeRO-offload&zhida_source=entity) 应该尽量满足以下三个方面，从而达到性能最优。

1.  尽可能减少 CPU 的计算，避免 CPU 的计算成为性能瓶颈
2.  尽可能减少 CPU-GPU 之间的通讯，避免通讯开销成为性能瓶颈
3.  在最小化通讯量的同时，尽可能多的节省 GPU 的显存

一般而言，CPU 的内存可以远大于 GPU 的显存，因此可以将占据空间最大的优化器状态、FP32的模型参数 offload 到 CPU。这两部分可以节省 12M bytes的空间。同时，由于参数的更新，相比于模型的前向后向传播，计算量小很多。因此，可以将模型参数更新，使用 CPU 进行计算。

| 数据 offload | 计算 offload      |                                                                                                                                                                |
| ---------- | --------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| GPU        | FP16的模型参数、中间激活  | 前向传播和[后向传播](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=2&q=%E5%90%8E%E5%90%91%E4%BC%A0%E6%92%AD&zhida_source=entity) |
| CPU        | FP32的模型参数、优化器状态 | 优化器更新模型参数                                                                                                                                                      |

通讯量：fp16的梯度和模型的参数。

使用ZeRO-offload 后，模型训练的数据流如下[\[4\]](#ref_4)：

![](https://pic4.zhimg.com/v2-3015c312e34307aa9b910b402b1e12c7_1440w.jpg)

ZeRO-Offload: Democratizing Billion-Scale Model Training

### 2.4 ZeRO与数据并行的关系

ZeRO算法，在大部分情况下，也可以理解为数据并行。在 deepspeed中，有个特殊的 stage-0，这种情况下，ZeRO 算法等价于 DDP 算法，也就是1.3 提到的 All-Reduce算法。而在stage-3中，会将模型的参数也进行分片，可以理解为模型的并行。而 stage-1 和stage-2 则只是将优化器参数、梯度等进行了分片。可以看作是特殊的数据并行。因此，1.3 中针对数据并行的提升效率的方法，也可以和 ZeRO 算法一起使用。

## 3、pipeline 并行

当模型太大，无法在单节点保存整个模型时，就需要将模型进行拆分。将模型按照不同层切分，分布在不同的节点的方法，称为 pipline 并行。

### 3.1 Naive pipline

最简单的方法，是将模型的不同层，依次放到不同的节点上，然后依次进行前向和后向计算。这种方式逻辑很简单，但是效率很低。任何一个时刻，都只有一个节点在工作。假设一共有P个节点，则流水线气泡占比为： (P-1)/P 。

![](https://pic3.zhimg.com/v2-b0fc2152f4ad3f3beafb39235b001b44_1440w.jpg)

Naive pipline

### 3.2 GPipe

为了提升节点的利用率，GPipe 对 Naive pipline 方式进行了改进[\[5\]](#ref_5)。方式是将一个batch，继续拆分为 M 个[micro batch](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=micro+batch&zhida_source=entity)，当节点 0 计算完成 F\_0 之后，节点1 可以开始进行计算 F\_0 ，而此时节点0 可以继续计算 F\_1 ，减少了节点资源的空闲。对于 P 个节点，M 个micro batch的 pipline，流水线气泡占比： $(P-1)/(P-1+M)$ 。当 $M \ge 4*P$ 时，气泡的开销可以基本忽略。

![](https://pic2.zhimg.com/v2-5954d806159be5b5144ac1b2b4e0984d_1440w.jpg)

GPipe

**GPipe 的缺点：**

1.  GPipe 是先全部进行前向计算，然后再进行反向计算，这样在全部计算完成前向计算之后，需要保存很多的中间状态，会有一个显存的峰值。
2.  micro batch 的个数 $M=batch\_size/micro\_batch\_size$ ，为了降低流水线气泡，需要比较大的M，而 [micro\_batch\_size](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=micro_batch_size&zhida_source=entity) 也不能特别小，如果特别小，则无法很好利用GPU中的[并行计算](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97&zhida_source=entity)能力（参见1.3.3中的分析）。因此，GPipe为了能有比较好的性能，需要有比较大的 batch\_size。这样同样需要较大的显存。
3.  pipline 并行，会将不同的层，切分到不同的节点上。因此，需要让每一块的节点上的计算量比较均衡，降低等待时间。这一点对于 transformer 结构比较友好，但对于其他的模型结构，也需要作为一个考量。

**激活重计算**

GPipe 对于显存有比较高的要求，因此需要对显存进行优化。在GPipe中，采用了[激活重计算](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=2&q=%E6%BF%80%E6%B4%BB%E9%87%8D%E8%AE%A1%E7%AE%97&zhida_source=entity)的方法来降低显存需求。对于 l 层transformer模型，中间激活占用的显存大小可以近似为$(34bsh+5bs^2a)*l$ [[6]](#ref_6)。以GPT3为例，模型参数 175B，需要显存 350GB。当序列长度s为2048时，对比不同的 batch size 占用的中间激活如下：

|batch size|中间激活占用显存|模型参数显存的倍数|
|---|---|---|
|1|275GB|0.79倍|
|64|17.6TB|50倍|
|128|35.3TB|101倍|

可以看到随着 batch size 的增大，中间激活占用的显存远远超过了模型参数显存。而GPipe又需要增大 batch size，来减小流水线气泡。因此采用激活重计算，是一个可以缓解对显存需求的方法。

一般而言，前向计算需要1个时间单元的话，反向计算会需要2个时间单元（对输入和参数分别进行求导）。进行激活重计算，会增加一次前向计算，大约会带来额外 33% 的计算。算是一种用计算换取空间的方法。

### 3.3 PipeDream

GPipe 中一个缺点是在显存中存储了很多的前向计算的中间结果，造成了显存峰值。还有一种改进方式，是尽早进行反向计算，从而尽早释放相关的显存。PipeDream就采用了这种方式[\[7\]](#ref_7)。当第一次前向传播完成时，就开始进行第一次反向传播，从而降低了对峰值显存的要求。

![|850](https://pic2.zhimg.com/v2-11e4d4623c3b292848ef270da6e72655_1440w.jpg)

PipeDream

## 4、张量并行

将模型的 layer 中的参数矩阵，进行拆分的方法，称为张量并行。

把矩阵按照行和列分别进行拆分，又可以分别称为“行并行”和“列并行”。具体的示意图如下所示。

![|775](https://pic2.zhimg.com/v2-64d57e4f8ecc9d67fabb7458f7c6247f_1440w.jpg)

行并行和列并行

### 4.1 MLP 的张量并行

**切分方式：**

-   采用“列并行”对第一个矩阵进行切分，采用“行并行”对第二个矩阵进行切分。
-   第一个[矩阵计算](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=%E7%9F%A9%E9%98%B5%E8%AE%A1%E7%AE%97&zhida_source=entity)的结果，刚好可以作为第二个矩阵计算的输入，减少了通讯的次数。

**通讯：**

-   g操作：在前向传递过程中，进行一次all reduce操作
-   f操作：在反向传递过程中，进行一次all reduce操作

![|725](https://pic4.zhimg.com/v2-4890e5ef198bd93ba3e907969db02151_1440w.jpg)

Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism

### 4.2 self-attention 的张量并行

**切分方式：**

-   采用“列并行”对Q、K、V[相关矩阵](https://zhida.zhihu.com/search?content_id=231938162&content_type=Article&match_order=1&q=%E7%9B%B8%E5%85%B3%E7%9F%A9%E9%98%B5&zhida_source=entity)进行切分，采用“行并行”对线性层的权重进行切分。

**通讯：**

-   g操作：在前向传递过程中，进行一次all reduce操作
-   f操作：在反向传递过程中，进行一次all reduce操作

![|650](https://pic1.zhimg.com/v2-f682e200e0c40f1a22bbc7aa0d0c8f52_1440w.jpg)

Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism

### 4.3 整体结构

单个transformer layer 在一次前向和后向计算中，一共需要4次 all-reduce通信[\[8\]](#ref_8)。

![|725](https://pic4.zhimg.com/v2-ae7a339e9072889e3d718e4277e99aa7_1440w.jpg)

Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism

### **4.4 张量并行的缺点：**

-   需要针对不同的模型结构进行针对性实现
-   通讯很大，而且计算和通讯不能异步
-   GPU增多的时候，冗余性也增多，导致无法做到16块卡

## 5、3D混合并行

总结下不同并行方法的特点[\[9\]](#ref_9)

**数据并行：** 计算效率高、实现简单。

-   显存效率：每张卡上都保存了完整的模型、梯度、优化器状态，因此显存效率不高。可以通过ZeRO优化。
-   计算效率：当增加并行度时，单卡的计算量是恒定的，可以接近完美的线性扩展。但规约梯度的通信开销，与模型大小成正相关。

**张量并行：** 需要针对模型结构进行实现，实现难度大。

-   显存效率：随着并行度增加, 成比例地减少显存占用。可以将单个很大的 layer 进行切分。
-   计算效率：通讯很大，和层数是线性关系。而且计算和通讯不能异步，计算效率很低。

**流水线并行：** 通信成本最低。

-   显存效率：减少的显存与流水线并行度成正比。但流水线并行不会减少每层中间激活的显存占用。
-   计算效率：成本更低的点对点 (P2P) 通信。通信量与流水线GPU数是线性关系。

**综合对比：**

-   显存效率：模型并行 > 流水线并行 > 数据并行。
-   通信效率：流水线并行 > 数据并行 > 模型并行。

通过将上述的并行方法进行组合，并根据计算和通讯效率进行组合，从而可以实现3D 混合并行，从而训练更大的模型。一个32卡的3D混合并行示意图如下[\[10\]](#ref_10)。

![|600](https://pic1.zhimg.com/v2-b9a2ff8bdcd27a7d903d99827231de14_1440w.jpg)

## 参考

1.  [^](#ref_1_0)Scaling Distributed Machine Learning with the Parameter Server [https://web.eecs.umich.edu/~mosharaf/Readings/Parameter-Server.pdf](https://web.eecs.umich.edu/~mosharaf/Readings/Parameter-Server.pdf)
2.  [^](#ref_2_0)PyTorch Distributed: Experiences on Accelerating Data Parallel Training [https://arxiv.org/abs/2006.15704](https://arxiv.org/abs/2006.15704)
3.  [^](#ref_3_0)ZeRO: Memory Optimizations Toward Training Trillion Parameter Models [https://arxiv.org/abs/1910.02054](https://arxiv.org/abs/1910.02054)
4.  [^](#ref_4_0)ZeRO-Offload: Democratizing Billion-Scale Model Training [https://arxiv.org/abs/2101.06840](https://arxiv.org/abs/2101.06840)
5.  [^](#ref_5_0)GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism [https://arxiv.org/abs/1811.06965](https://arxiv.org/abs/1811.06965)
6.  [^](#ref_6_0)分析transformer模型的参数量、计算量、中间激活、KV cache - 回旋托马斯x的文章 [https://zhuanlan.zhihu.com/p/624740065](https://zhuanlan.zhihu.com/p/624740065)
7.  [^](#ref_7_0)PipeDream: Fast and Efficient Pipeline Parallel DNN Training [https://arxiv.org/abs/1806.03377](https://arxiv.org/abs/1806.03377)
8.  [^](#ref_8_0)Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism [https://arxiv.org/abs/1909.08053](https://arxiv.org/abs/1909.08053)
9.  [^](#ref_9_0)\[PPT\]浅析大语言模型从预训练到微调的技术原理 - 回旋托马斯x的文章 [https://zhuanlan.zhihu.com/p/647843722](https://zhuanlan.zhihu.com/p/647843722)
10.  [^](#ref_10_0)DeepSpeed: Extreme-scale model training for everyone [https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/](https://www.microsoft.com/en-us/research/blog/deepspeed-extreme-scale-model-training-for-everyone/)