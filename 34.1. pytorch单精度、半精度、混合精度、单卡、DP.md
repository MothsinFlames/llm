---
created: 2025-09-29T16:16:00 (UTC +08:00)
tags: [分布式训练,数据并行,模型并行]
source: https://zhuanlan.zhihu.com/p/667458523
author: 关于作者胖胖大海深度不学习，算了吧工程师回答22文章10关注者94关注发私信
---

# pytorch单精度、半精度、混合精度、单卡、DP

> ## Excerpt
> pytorch单精度、半精度、混合精度、单卡、多卡（DP / DDP）、FSDP、DeepSpeed（环境没搞起来）模型训练代码，并对比不同方法的训练速度以及GPU内存的使用 GitHub - xxcheng0708/pytorch-model-train-template: pyt…

---
pytorch单精度、半精度、混合精度、单卡、多卡（DP / DDP）、FSDP、DeepSpeed（环境没搞起来）模型训练代码，并对比不同方法的训练速度以及GPU内存的使用

___

### **[FairScale](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=FairScale&zhida_source=entity)（你真的需要FSDP、DeepSpeed吗？）**

在了解各种训练方式之前，先来看一下 FairScale 给出的一个模型训练方式选择的流程，选择适合自己的方式，就是最好的。

![](https://pic1.zhimg.com/v2-58210dbb08dedde84a8a409b4fbc4c4a_1440w.jpg)

___

### **训练环境设置**

-   模型：预训练的[Resnet50](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=Resnet50&zhida_source=entity)
-   数据集：[Cifar10](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=Cifar10&zhida_source=entity)
-   硬件资源：一台4卡[Tesla P40](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=Tesla+P40&zhida_source=entity)
-   训练设置：5 epoch、128 batch size
-   观察指标：显存占用、GPU使用率、训练时长、模型训练结果

**备注：** 1. 由于P40硬件限制，不支持半精度fp16的训练，在fp16条件下训练的速度会受到影 响 2. ResNet50模型较小，batch\_size=1时单卡仅占用 0.34G显存，绝大部分显存都被输入数据，以及中间激活占用

___

### **测试基准（batch\_size=1）**

-   单卡显存占用：0.34 G
-   单卡GPU使用率峰值：60%

___

### **单卡单精度训练**

-   代码文件：pytorch\_SingleGPU.py
-   单卡显存占用：11.24 G
-   单卡GPU使用率峰值：100%
-   训练时长（5 epoch）：1979 s
-   训练结果：准确率85%左右

![](https://pic2.zhimg.com/v2-15330d11003d1259b300ea032f8d9d77_1440w.jpg)

___

### **单卡半精度训练**

-   代码文件：pytorch\_half\_precision.py
-   单卡显存占用：5.79 G
-   单卡GPU使用率峰值：100%
-   训练时长（5 epoch）：1946 s
-   训练结果：准确率75%左右

![](https://pic4.zhimg.com/v2-372f168f761ef08150db944cbd37b201_1440w.jpg)

**备注：** 单卡半精度训练的准确率只有75%，单精度的准确率在85%左右

___

### **单卡混合精度训练**

[AUTOMATIC MIXED PRECISION PACKAGE - TORCH.AMP](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/amp.html%23torch.autocast)

[CUDA AUTOMATIC MIXED PRECISION EXAMPLES](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/notes/amp_examples.html%23amp-examples)

[PyTorch 源码解读之 torch.cuda.amp: 自动混合精度详解](https://zhuanlan.zhihu.com/p/348554267)

[如何使用 PyTorch 进行半精度、混(合)精度训练](https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_44089890/article/details/130471991)

[如何使用 PyTorch 进行半精度训练](https://link.zhihu.com/?target=https%3A//blog.csdn.net/qq_39845931/article/details/121671342)

[pytorch模型训练之fp16、apm、多GPU模型、梯度检查点（gradient checkpointing）显存优化等](https://zhuanlan.zhihu.com/p/448395808)

[Working with Multiple GPUs](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/notes/amp_examples.html%23amp-multigpu)

-   代码文件：pytorch\_auto\_mixed\_precision.py
-   单卡显存占用：6.02 G
-   单卡GPU使用率峰值：100%
-   训练时长（5 epoch）：1546 s
-   训练结果：准确率85%左右

![](https://pic2.zhimg.com/v2-56e191e046750a88c10760a9b07aad01_1440w.jpg)

-   混合精度训练过程

![](https://pica.zhimg.com/v2-95200e23cb9cae4589d49745ee6c3a72_1440w.jpg)

-   混合精度训练基本流程
-   维护一个 FP32 数值精度模型的副本
-   在每个iteration
    

-   拷贝并且转换成 FP16 模型
-   前向传播（FP16 的模型参数）
-   loss 乘 scale factor s
-   反向传播（FP16 的模型参数和参数梯度）
-   参数梯度乘 1/s
-   利用 FP16 的梯度更新 FP32 的模型参数

-   autocast结合[GradScaler](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=GradScaler&zhida_source=entity)用法
    

```text
# Creates model and optimizer in default precision
model = Net().cuda()
optimizer = optim.SGD(model.parameters(), ...)

# Creates a GradScaler once at the beginning of training.
scaler = GradScaler()

for epoch in epochs:
    for input, target in data:
        optimizer.zero_grad()

        # Runs the forward pass with autocasting.
        with autocast(device_type='cuda', dtype=torch.float16):
            output = model(input)
            loss = loss_fn(output, target)

        # Scales loss.  Calls backward() on scaled loss to create scaled gradients.
        # Backward passes under autocast are not recommended.
        # Backward ops run in the same dtype autocast chose for corresponding forward ops.
        scaler.scale(loss).backward()

        # scaler.step() first unscales the gradients of the optimizer's assigned params.
        # If these gradients do not contain infs or NaNs, optimizer.step() is then called,
        # otherwise, optimizer.step() is skipped.
        scaler.step(optimizer)

        # Updates the scale for next iteration.
        scaler.update()
```

-   基于GradScaler进行梯度裁剪

```text
scaler.scale(loss).backward()
scaler.unscale_(optimizer)
torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)
scaler.step(optimizer)
scaler.update()
```

-   autocast用法

```text
# Creates some tensors in default dtype (here assumed to be float32)
a_float32 = torch.rand((8, 8), device="cuda")
b_float32 = torch.rand((8, 8), device="cuda")
c_float32 = torch.rand((8, 8), device="cuda")
d_float32 = torch.rand((8, 8), device="cuda")

with torch.autocast(device_type="cuda"):
    # torch.mm is on autocast's list of ops that should run in float16.
    # Inputs are float32, but the op runs in float16 and produces float16 output.
    # No manual casts are required.
    e_float16 = torch.mm(a_float32, b_float32)
    # Also handles mixed input types
    f_float16 = torch.mm(d_float32, e_float16)

# After exiting autocast, calls f_float16.float() to use with d_float32
g_float32 = torch.mm(d_float32, f_float16.float())
```

-   autocast嵌套使用

```text
# Creates some tensors in default dtype (here assumed to be float32)
a_float32 = torch.rand((8, 8), device="cuda")
b_float32 = torch.rand((8, 8), device="cuda")
c_float32 = torch.rand((8, 8), device="cuda")
d_float32 = torch.rand((8, 8), device="cuda")

with torch.autocast(device_type="cuda"):
    e_float16 = torch.mm(a_float32, b_float32)
    with torch.autocast(device_type="cuda", enabled=False):
        # Calls e_float16.float() to ensure float32 execution
        # (necessary because e_float16 was created in an autocasted region)
        f_float32 = torch.mm(c_float32, e_float16.float())

    # No manual casts are required when re-entering the autocast-enabled region.
    # torch.mm again runs in float16 and produces float16 output, regardless of input types.
    g_float16 = torch.mm(d_float32, f_float32)
```

___

### **4卡 DP（[Data Parallel](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=Data+Parallel&zhida_source=entity)）**

-   代码文件：pytorch\_DP.py
-   单卡显存占用：3.08 G
-   单卡GPU使用率峰值：99%
-   训练时长（5 epoch）：742 s
-   训练结果：准确率85%左右

![](https://picx.zhimg.com/v2-0aff541b1becd74f048ccdf98dee203d_1440w.jpg)

___

### **4卡 DDP（[Distributed Data Parallel](https://zhida.zhihu.com/search?content_id=236454307&content_type=Article&match_order=1&q=Distributed+Data+Parallel&zhida_source=entity)）**

[pytorch-multi-gpu-training /ddp\_train.py](https://link.zhihu.com/?target=https%3A//github.com/jia-zhuang/pytorch-multi-gpu-training/blob/master/ddp_train.py)

[DISTRIBUTED COMMUNICATION PACKAGE - TORCH.DISTRIBUTED](https://link.zhihu.com/?target=https%3A//pytorch.org/docs/stable/distributed.html)

-   代码文件：pytorch\_DDP.py
-   单卡显存占用：3.12 G
-   单卡GPU使用率峰值：99%
-   训练时长（5 epoch）：560 s
-   训练结果：准确率85%左右

![](https://pic1.zhimg.com/v2-6e4ca5d847587358636f8b07b9868ee0_1440w.jpg)

-   代码启动命令（单机 4 GPU）

```text
python -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 pytorch_DDP.py
```

___

### **基于accelerate的 DDP**

[huggingface/accelerate](https://link.zhihu.com/?target=https%3A//github.com/huggingface/accelerate)

[Hugging Face开源库accelerate详解](https://link.zhihu.com/?target=https%3A//blog.csdn.net/cxx654/article/details/131817042%3Fspm%3D1001.2014.3001.5501)

-   代码文件：accelerate\_DDP.py
-   单卡显存占用：3.15 G
-   单卡GPU使用率峰值：99%
-   训练时长（5 epoch）：569 s
-   训练结果：准确率85%左右

![](https://pic2.zhimg.com/v2-68ba671292f378407c98f05656942139_1440w.jpg)

-   accelerate配置文件default\_DDP.yml

```text
compute_environment: LOCAL_MACHINE
distributed_type: MULTI_GPU
downcast_bf16: 'no'
gpu_ids: all
machine_rank: 0
main_training_function: main
mixed_precision: 'no'
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```

-   代码启动命令（单机 4 GPU）

```text
accelerate launch --config_file ./config/default_DDP.yml accelerate_DDP.py
```

___

### **Pytorch + FSDP（Fully Sharded Data Parallel）**

[Pytorch FULLY SHARDED DATA PARALLEL (FSDP) 初识](https://zhuanlan.zhihu.com/p/620333654)

[2023 年了，大模型训练还要不要用 PyTorch 的 FSDP ？](https://link.zhihu.com/?target=https%3A//cloud.tencent.com/developer/article/2314837)

[GETTING STARTED WITH FULLY SHARDED DATA PARALLEL(FSDP)](https://link.zhihu.com/?target=https%3A//pytorch.org/tutorials/intermediate/FSDP_tutorial.html)

-   batch\_size == 1
    

-   单卡显存占用：0.19 G，相比基准测试的 0.34G 有减少，但是没有达到4倍
-   单卡GPU使用率峰值：60%

-   batch\_size == 128
    

-   单卡显存占用：2.88 G
-   单卡GPU使用率峰值：99%

-   代码文件：pytorch\_FSDP.py
-   训练时长（5 epoch）：581 s
-   训练结果：准确率85%左右

**备注：** pytorch里面的FSDP的batchsize是指单张卡上的batch大小

**注意：** to save the FSDP model, we need to call the state\_dict on each rank then on Rank 0 save the overall states.翻译过来就是使用下面形式的代码来保存FSDP模型（否则，保存模型的时候会卡主）：

```text
states = model.state_dict()
    if rank == 0:
        torch.save(states, "model.pt") 
```

![](https://pic3.zhimg.com/v2-408b261404c11ae385a79711d285fed0_1440w.jpg)

-   代码启动命令（单机 4 GPU）

```text
python -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 pytorch_FSDP.py
```

-   FSDP包装后的模型

代码中指定对Resnet50中的Linear和Conv2d层应用FSDP。

![](https://pica.zhimg.com/v2-0bf4ebb66c1644dd0a9ce5a4902cb2a8_1440w.jpg)

___

### **基于accelerate的 FSDP（Fully Sharded Data Parallel）**

-   batch\_size == 1
    

-   单卡显存占用：0.38 G，相比基准测试的 0.34G 并没有减少
-   单卡GPU使用率峰值：60%

-   batch\_size == 128
    

-   单卡显存占用：2.90 G
-   单卡GPU使用率峰值：99%

-   代码文件：accelerate\_FSDP.py
    
-   训练时长（5 epoch）：576 s，对于这个小模型速度和DDP相当
-   训练结果：准确率85%左右

![](https://pic1.zhimg.com/v2-12eafa1f44ee02a0d5d6831169ac6024_1440w.jpg)

-   accelerate配置文件default\_FSDP.yml

```text
compute_environment: LOCAL_MACHINE
distributed_type: FSDP
downcast_bf16: 'no'
fsdp_config:
  fsdp_auto_wrap_policy: SIZE_BASED_WRAP
  fsdp_backward_prefetch_policy: BACKWARD_PRE
  fsdp_forward_prefetch: true
  fsdp_min_num_params: 1000000
  fsdp_offload_params: false
  fsdp_sharding_strategy: 1
  fsdp_state_dict_type: SHARDED_STATE_DICT
  fsdp_sync_module_states: true
  fsdp_use_orig_params: true
machine_rank: 0
main_training_function: main
mixed_precision: 'no'
num_machines: 1
num_processes: 4
rdzv_backend: static
same_network: true
tpu_env: []
tpu_use_cluster: false
tpu_use_sudo: false
use_cpu: false
```

-   代码启动命令（单机 4 GPU）

```text
accelerate launch --config_file ./config/default_FSDP.yml accelerate_FSDP.py
```

___

### **Pytorch + DDP + ZeRO（Zero Redundancy Optimizer）**

-   代码文件：pytorch\_DDP\_ZeRO.py
-   单卡显存占用：3.18 G
-   单卡GPU使用率峰值：99%
-   训练时长（5 epoch）：596 s
-   训练结果：准确率95%左右（使用Adam优化算法）

![](https://pic3.zhimg.com/v2-5246b131f6949157e937e83431820a20_1440w.jpg)

-   代码启动命令（单机 4 GPU）

```text
python -m torch.distributed.launch --nproc_per_node=4 --nnodes=1 pytorch_DDP_ZeRO.py --use_zero
```

___

### **Pytorch + DeepSpeed（环境没搞起来，哈哈哈）**

[\[BUG\] error: unrecognized arguments: --deepspeed ./ds\_config.json #3961](https://link.zhihu.com/?target=https%3A//github.com/microsoft/DeepSpeed/issues/3961)

[fused\_adam.so: cannot open shared object file: No such file or directory #119](https://link.zhihu.com/?target=https%3A//github.com/databrickslabs/dolly/issues/119)

[DeepSpeedExamples/training/cifar/](https://link.zhihu.com/?target=https%3A//github.com/microsoft/DeepSpeedExamples/tree/master/training/cifar)

[Getting Started](https://link.zhihu.com/?target=https%3A//www.deepspeed.ai/getting-started/)

-   代码文件：pytorch\_DeepSpeed.py
-   单卡显存占用：
-   单卡GPU使用率峰值：
-   训练时长（5 epoch）：
-   训练结果：
    
-   代码启动命令（单机 4 GPU）
    

```text
deepspeed pytorch_DeepSpeed.py --deepspeed_config ./config/zero_stage2_config.json
```

___

### **基于accelerate的 DeepSpeed（环境没搞起来，哈哈哈）**

[DeepSpeed介绍](https://zhuanlan.zhihu.com/p/624412809)

[深度解析：如何使用DeepSpeed加速PyTorch模型训练](https://link.zhihu.com/?target=https%3A//blog.51cto.com/u_16213376/7408723)

[DeepSpeed](https://link.zhihu.com/?target=https%3A//huggingface.co/docs/accelerate/usage_guides/deepspeed)

-   代码文件：accelerate\_DeepSpeed.py
-   单卡显存占用：
-   单卡GPU使用率峰值：
-   训练时长（5 epoch）：
-   训练结果：

___

### **模型保存**

详见各方法的训练代码文件。

-   单卡训练保存

```text
torch.save(model.state_dict(), model_name)
```

-   多卡训练保存

```text
torch.save(model.module.state_dict(), model_name)
```

-   FSDP训练保存

```text
states = model.state_dict()
    if rank == 0:
        torch.save(states, model_name)
```

___

### **模型推理**

详见model\_inference.py代码文件

___

### **onnx模型导出 / onnxruntime推理**

[pytorch.onnx.export方法参数详解，以及onnxruntime-gpu推理性能测试](https://link.zhihu.com/?target=https%3A//blog.csdn.net/cxx654/article/details/123011332)

详见model\_inference.py代码文件
