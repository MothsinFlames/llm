---
created: 2025-09-02T20:51:13 (UTC +08:00)
tags: [qwen,qwen3,AI]
source: https://zhuanlan.zhihu.com/p/1902064402053695444
author: 关于作者JioNLP开源JioNLP、ffio作者，公众号JioNLP紫气东来、郭达森也关注了她回答135文章67关注者11,836关注她发私信
---
最近 [Qwen3.0](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=Qwen3.0&zhida_source=entity) 在 4月30号紧急上新了，我梳理一下这两年 Qwen都做了一些什么，发展路径是什么。

| Qwen      | 1.0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 2.0                                                                                                                                                                                                                                                          | 2.5                                                                                                                                                                                                                                                                                                                                                   | 3.0               |
| --------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------- |
| 发布时间      | 2023.9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | 2024.7                                                                                                                                                                                                                                                       | 2024.12                                                                                                                                                                                                                                                                                                                                               | 2025.5            |
| 旗舰模型      | \-                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | Qwen2.0-70B                                                                                                                                                                                                                                                  | Qwen2.5-72B-Instruct                                                                                                                                                                                                                                                                                                                                  | Qwen3.0-235B-A22B |
| 词表        | 152K                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 148K                                                                                                                                                                                                                                                         | 148K                                                                                                                                                                                                                                                                                                                                                  | 148K              |
| token训练量  | 3T                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          | 7T                                                                                                                                                                                                                                                           | 18T                                                                                                                                                                                                                                                                                                                                                   | **36T**           |
| context长度 | 2048                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        | 32K（128K[Yarn](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=Yarn&zhida_source=entity)）                                                                                                                           | 32K（128KYarn）                                                                                                                                                                                                                                                                                                                                         | 32K（128KYarn）     |
| 微调数据量     | 30万                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         | 50万                                                                                                                                                                                                                                                          | 上百万                                                                                                                                                                                                                                                                                                                                                   | \-                |
| 关键技术      | [untied embedding](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=untied+embedding&zhida_source=entity)、[rope](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=rope&zhida_source=entity)、[pre-Norm](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=pre-Norm&zhida_source=entity)、[RMSNorm](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=RMSNorm&zhida_source=entity)、[silu](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=silu&zhida_source=entity)、PPO | MoE、[GQA](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=GQA&zhida_source=entity)、[DCA](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=DCA&zhida_source=entity)、Yarn、DPO | scaling law、[offline 和 online 两阶段RL](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=offline+%E5%92%8C+online+%E4%B8%A4%E9%98%B6%E6%AE%B5RL&zhida_source=entity)、[AWQ量化](https://zhida.zhihu.com/search?content_id=257286258&content_type=Article&match_order=1&q=AWQ%E9%87%8F%E5%8C%96&zhida_source=entity) | 深度推理              |

整体上，Qwen 的发展主要体现在以下几点：

-   **模型规模从小到大**：主要体现在：

-   预训练数据集越来越大，从**3Ttoken，逐步发展到2.5版本的18T，3.0版本的36T**；
-   模型参数规模：最早就是主打**7B**，现在就不仅仅是7B了，还包括了 **235B**参数；并在2.5版本开始着手验证scaling law。
-   对齐阶段SFT的数据量，最早30万条，现在也已经上百万条了。

-   **不断考虑训练推理效率**：

-   像初代版本还用的是dense FFL，此后就演变成了 **MoE**模型，加快了训练和推理效率；
-   注意力机制计算也采用了 **GQA**技术，减少计算量；
-   扩展上下文长度也新增了 **DCA** 和 **Yarn**，总之不是蛮力扩展上下文长度，而是采用了技巧，目的也是为了节省计算资源。
-   对齐阶段，PPO 也被改成了 **DPO**, RSPO，同样是省去了复杂的强化模型训练框架。
-   推理阶段给出了 **AWQ** 量化策略，同样是为了保证效果的同时，兼顾效率。
-   **向数学、编程发展**：众所周知，数学和编程这两样对于语言模型来说，比较难，是不少公司发力研发的目标。
	-   数据组织大幅提高数学、编程的数据占比。
	-   为了控制数学、编程输出结果的稳定性、确定性，在对齐阶段也采用了offline和 online 两种方式。
	-   **诟病**：数学和编程能力确实在2.5、3.0版本中有提升，但大量用户反馈，在写报告、回答常识问题、复述一些用户问话、处理简单日常任务能力上，返回幻觉频发，参数量增加了，但效果更差了。这种情况也不是Qwen 一家如此。似乎数学和编程这类问题和日常常识问答存在一些思维方式上的矛盾。
-   **深度思考**：深度思考现在几乎每家模型都需要接入了，因为这个过程必不可少：
	-   深度思考其实是 decoder-only 模型弥补相对于 encoder-decoder 模型不足的一种补充；
	-   深度思考也是解决复杂问题，包括编程、数学、agent 等必不可少的一关；
	-   深度思考是语言表示思维的必经步骤。

## 后续发展
-   **对齐方式的变革**：前面的那个**诟病**其实已经很多了，许多用户在反馈幻觉越来越重，归根结底，还是在对齐训练阶段，模型出现了灾难性遗忘。不论是什么微调方式，难训练的点就在这里。理想情况下，模型训练微调的参数量应该极少极少，应该远远比 对齐阶段 PPO 和 DPO 方式中调整policy 的参数量更少，而且避免模型遗忘才对。这需要新的技术出现来引领。
-   **下游任务训练**：Qwen 每次都发布了许多尺寸的模型，0.6B、1.5B、3B、7B、14B、32B、72B、235B等等。许多公司都会拿这些模型做下游任务微调训练，但说实话，真正能训练好、用好、投入使用，还是少数。许多人都是跟风、到最后AI垂直应用搞得一地鸡毛。归根结底，**Qwen 需要在下游任务训练上发力，研发出更高效，更牛逼的微调任务训练方法出来**，这样，模型开源的生态才会发展壮大。

接下来按版本简单列一下关键信息点：

## Qwen1.0
## 数据
-   通过爬虫，降重等等操作，最终形成高质量数据3T token。

## Tokenizer

-   沿袭GPT4，采用了BPE算法，最终词表 152K，相比其它公司的tokenizer，压缩效率更高，token数量会更短。

## 模型

-   沿用 LLama 基础模型结构，但做了如下调整：
-   使用了untied embedding （输入和输出 token embedding 使用相同的一套参数表示）方式（有不少论文论证 tying embedding 训练效果存疑）
-   采用了 RoPE 方法（循环相对位置编码），并且配合 RoPE，在 QKV里保留了 Bias 项
-   采用了 Pre-Norm 和 RMSNorm
-   采用了 SwiGLU 激活层，也没具体说参数，看样子就是 silu 函数。

## 预训练

-   扩展上下文长度2048。采用了NTK-aware 插值。
-   注意力机制采用了两种策略 LogN-Scaling 和 Window 来限制关注的长度，而且窗口长度给不同层设置也不一样。

## 对齐

-   模型对齐的前提还是在准备许多监督数据集，不详述了。
-   SFT 这个没什么好说的，必须尝试的方法。

### RLHF

-   PMP 偏好模型预训练，让模型比对数据，知道什么是好，什么是差。
-   RM 奖励模型，根据提供的结果表格看，Qwen的 RM 准确率相当高，到了74%。还是PPO那一套，只不过在训练时有一些策略：
	-   优先训练 value model 也就是critic model ，然后再同步训练policy model，也就是actor model。其目的也是为了训练的稳定性。
	-   对于每一个query，也就是prompt，采样两次结果，其实就是生成两个response。
	-   训练时，考虑到稳定性，PPO算法中的value loss clipping设置比较窄，而推理时又放宽了。
	-   通过引入预训练梯度和合理设置 KL 惩罚系数，可以在减轻对齐成本的同时，确保模型在不同基准测试中的性能。 Agent工具使用、代码编写、数学问题

-   我感觉Qwen 1.0 没什么特别出众的效果。应该只是1.0版本的一次尝试。更何况，LLM 编程是个什么水平，我们大家都清楚，这里就不再细说了。
-   只是代码编写模型是重新训练的，和上面的预训练模型不是一个，而且数据量只是900亿 tiken，但考虑到代码冗长，需要设置更长的上下文8196。这样一来，模型效果自然就不会特别好。

## Qwen1.5

1.5版本属于是从1.0衍生来的。没有论文，只有模型和blog 介绍。归纳改进内容如下：

-   Context 大幅度扩展至 32768（32K）。真的可以说长上下文太关键了。
-   qwen推出了许多小于7B的模型，在1.5版本中，qwen小于7B的模型成为了业界最先进的版本。 MoE
-   2.7B参数专家混合系统，性能却相当于7B。训练成本和推理速度都有很大的优化。

## Qwen2.0

2.0版本可以说是深度参与了模型参数开源，并主打了 Qwen2.0-72B 旗舰模型。

## 数据

-   数据清洗更上一个台阶，什么过滤算法、预处理手段统统往上怼。
-   数据总量扩增到了 7T token。但是我看论文说千问还尝试了12万亿的数据量，但并没有取得好的效果。感觉像是模型规模没跟上。

## Tokenizer

-   词表大小成了 148K，比1.0稍微短一些，我猜是人工删掉了一些无意义词。这类词的产生还是跟数据不够干净有关。

## 模型

-   Context 大幅度扩展至 32768（32K）。 整体上看，随着模型上下文变长，模型需要变得稀疏、压缩计算量，于是就有了如下变更：
-   Grouped Query Attention：分组查询注意力机制，可以压缩KV匹配的计算量。看样子是上下文变长之后，训练和推理计算量太大，为了应对KV开销太大的一种策略，很自然的事情。
-   Dual Chunk Attention with YARN：同样是由于上下文变长了，采取的一种应对策略，并且扩增了上下文长度。分块注意力机制同样是降低了密集KV计算的复杂度。YARN 的目的在于，上下文变长了，就会导致该被注意力机制注意到的突出token 被淹没在大量的token 当中，所以YARN 可以扩增突出作用。
-   2.0版本也沿用了 1.5版本中的 MoE模型，其实也就是把模型密集 FFN 层搞稀疏。

## 对齐

Qwen2.0 把对齐这块叫 Post-training，咱也不知道这里怎么又起了个新名字。对齐也挺难的，一个是1.0版本我认为Qwen的对齐做的没有很突出。另一个是，对齐需要高质量的数据，以及人工标注反馈信息，这数据量肯定就没有预训练那么丰富。

-   扩增指令微调数据集的广泛度
-   强化数学、编程指令微调效果：设计了一套细碎的方法来充分利用数据，不展开了。
-   SFT：50万样本量。
-   RLFH：没什么好说的，1.0版本里使用的是PPO，2.0这里用了 DPO（其实还是降低训练成本）还采用了Qwen自研的 Online Merging Optimizer。

## Qwen2.5

## 数据

-   18万亿的 token，并且大幅扩充了数学、编程、难题、多语言的数据。
-   2.0 已经有训练比较好的模型了，就拿老模型生成训练数据，左脚踩右脚逐步升天。

## Tokenizer

-   Tokenizer 词表没变，看来是优化差不多了。控制 token 从 3个变成22个。我猜是为了应对编程、agent等任务而设立的。

## 预训练

-   验证 scaling law：在模型结构给定情况下，找出最优超参数配置，学习率、batch size，模型大小，训练数据之间的关系。（这只能说明一个问题：阿里在千问上是真下本儿啊！！！）
-   长上下文预训练：先训练4096长度的模型，再扩展至32K。但是 Qwen2.5-Turbo 模型则更激进，扩展到了256K的上下文长度。再结合 Yarn 和 DCA，就可以再在这个长度基础上，扩展4倍。

## 对齐

-   SFT的对齐数据大幅扩增，达到上百万。但是根据报告，RL 阶段并没有用到长上下文的数据（因为论文称没必要，短数据就够了）。
-   强化学习分为了两个部分， offline RL（主要负责建立推理、事实、指令遵循能力） 和 online RL（主要建立输出质量、有用性、精简性、无害和无偏性）。之所以这么做，我猜想可能两大方面能力拟合的速度不同，后者如果用 offline 来拟合，上限不够高。

## 推理

-   提供了 AWQ 的量化方法。

## Qwen3.0

-   来吧，推理和 thinking 已经接入了，包括了推理思考过程。但首次在接口里提供了是否思考的无缝切换（对于有些任务，就需要深度思考，有些就不需要）。
-   主打模型：Qwen3-235B。上下文长度依然是32K，通过扩增可以达到 128K。

## 诟病

数学和编程一直是个比较难的领域。自从 Qwen2.0 开始，模型逐渐在向数学和编程方向发力。由此造成了在其它相对容易的领域（文学、新闻、电视、游戏等等）产生了大量的幻觉，这种幻觉现象也不仅仅是 Qwen 独有。许多模型都在逐渐出现类似的问题。
