---
created: 2025-09-02T16:22:27 (UTC +08:00)
tags: [数学模型,多模态大模型]
source: https://zhuanlan.zhihu.com/p/706216503
author: 关于作者404dreamerTitles cannot title me爱丁堡大学 语音与语言处理硕士回答0文章7关注者168关注他发私信
---

# 多模态大模型（理解）入门看这一篇就好了

> ## Excerpt
> 1 前言笔者第一次接触到understanding这个在AI领域的concept时还是在爱丁堡大学读Master时在NLU+（Natural Language Understanding）的课上，当时Professor Frank Keller在第一课对NLU的定义如下：Broadly: any co…

---
## 1 前言

笔者第一次接触到[understanding](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=understanding&zhida_source=entity)这个在AI领域的concept时还是在爱丁堡大学读Master时在[NLU](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=NLU&zhida_source=entity)+（Natural Language Understanding）的课上，当时Professor [Frank Keller](https://link.zhihu.com/?target=https%3A//scholar.google.com/citations%3Fuser%3D-lbtnAgAAAAJ%26hl%3Den)在第一课对NLU的定义如下：

> Broadly: any computational problem where the **input** is natural language, and the **output** is structured information that a computer can store (e.g. in a database) or execute (e.g. a command to a digital assistant)

简单来说，Understanding是一个比较泛泛的概念，相关于understanding的任务，可以简单理解为：**如何让模型去理解输入，从而去处理一些下游的任务**。

于是，我们很容易联想到，[Multimodality Understanding](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=Multimodality+Understanding&zhida_source=entity)的相关任务可以理解为**input**是多个模态的数据（例如，文本+图片），而**output**依然是sturctural information，其中structural information通常是以文本的方式呈现。

当下最热门的方向则是多模态大模型**[MLLM](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=MLLM&zhida_source=entity) (Multimodal Large Language Model)**: Multimodality Understanding与LLM (Large Language Model)的交集。

本文将通过梳理一篇survey来从understanding的视角归纳MLLM（主要为视觉和文本融合）现有的方法：

## 2 模型架构

MLLM通常包含以下三个组件：

-   A pre-trained modality encoder
-   A pre-trained LLM
-   A modality interface to connect them

### 2.1 Modality Encoder - 模态编码器

> The encoders compress raw information, such as images or audio, into a more compact representation.

模态编码器即将单一模态的输入转化成合适的representation（通常为latent embedding）。

视觉编码器与NLP中的Encoder类似，可以直接选择pre-train好的。其中比较常见的为通过[CLIP](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=CLIP&zhida_source=entity)（Contrastive Language-Image Pre-Training）训练好的encoder。CLIP通过对图像-文本对的大规模预训练，将视觉编码器在语义上与文本对齐。通过对齐预训练，使用这种最初预对齐的编码器与LLM的对齐更容易。

![](https://picx.zhimg.com/v2-bcca55ec6e8c9492359eac7feca75743_1440w.jpg)

常用的视觉编码器详情

在选择视觉编码器时，通常需要对**分辨率**、**模型参数量**和**编码器的预训练数据集**进行考虑。

许多工作已经实证证实，使用更高的分辨率可以获得显著的性能提高。其中不同架构对于处理不同分辨率（可以粗略分为高分辨率和低分辨率）的图片有着不同的策略。

-   **使用不同编码器编码后进行特征融合**：CogAgent使用了两个vision encoders去分别对高分辨率图片和低分辩率图片去进行编码，在得到高分辨率特征和低分辨率特征后，使用cross- attention进行高低分辨率特征融合。
-   **图片切片方法**（patch-division method）：将高分辨率图像分割成多个小块，再利用低分辨率编码器去进行。其中图片切片方法可能需要positional embedding去提示每个小块在原始图片中的相对位置。

在众多因素当中，图片分辨率的重要性要大于模型参数量和和训练数据组成。

### 2.2 Pre-trained LLM - 预训练大语言模型

LLM则为整个MLLM中可以说最核心的部分，根据现在口口相传的scaling law，理论上LLM的参数量可以决定上限（要不为何最近都在卷千亿大模型万亿大模型），但是实际上随着模型参数量如果训练策略不够有效，那么很有可能下限也会降低。所以，根据应用场景去选择一个合适参数量的LLM更为明智。

### 2.3 Modality Interface

考虑到以端到端方式训练大型多模态模型的成本很高，为了使用Pre-trained LLM和Pre-trained modality encoder，我们需要去设置一个模块，这个模块可以去将不同模态的经过encoder后的信息融合。

最为常见的方法为使用**Learnable Connector**和**Expert Model**.

**2.3.1 Learnable Connector**

通过learnable connector这个模块，可以将多模态信息融合成可以让LLM理解的信息。融合的模型可以根据融合的最小颗粒度划分：**token-level**和**feature-level**。

**2.3.1.1 Token-level Fusion**

> **For token-level fusion, features output from encoders are transformed into tokens and concatenated with text tokens before being sent into LLMs. A common and feasible solution is to leverage a group of learnable query tokens to extract information in a query-based manner**

对于在token层面的融合，modality encoder输出的特征会被转化成与LLM输入等价的token representation，通过将text token representation和其他模态转化后的token representation进行拼接，可以作为“可以被理解”的LLM输入。

比较经典的有：

![](https://pic2.zhimg.com/v2-77bf4cfa072a25019c984f9f2c0a8aa5_1440w.jpg)

Blip2: Q-former

> The queries interact with each other through self-attention layers, and interact with frozen image features through cross-attention layers (inserted every other transformer block). The queries can additionally interact with the text through the same self-attention layers.

-   **Q-former style (BLIP2)**: 引入learnable queries来缩小 (frozen) image encoder和LLM之间gap。具体通过共用的self-attention层。
-   **MLP (LLaVA)** : 通过MLP将视觉特征与文本特征对齐。

其中MM1 (from Apple)论文中发现:

模态适配器（对应上文提到的Q-former或是MLP）种类的对MLLM性能的影响远远不及**图像分辨率**和**visual tokens的数量**。

**2.3.1.2 Feature-level Fusion**

插入额外的模块（这里指在LLM里或者visual transformer中插入额外的layer），以实现文本特征和视觉特征之间的深度交互和融合。

-   [Flamingo](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=Flamingo&zhida_source=entity)在LLM中插入了额外的cross-attention层去加强语言模态与视觉模态的融合。

**由此可知，feature-level fusion和token-level fusion的本质区别在于是否更改LLM或是ViT的内部结构：若是仅在两个组件之间增加一个额外的组件（例如Q-former）则是token-level fusion；若是更改了LLM或是ViT的内部结构，例如加入了额外的模态融合层，则是feature-level fusion。**

**2.3.2 Expert Model**

专家模型，例如image caption模型，可以将图片转化成描述文字，这样多模态的输入可以被转化成单模态的输入。由此只需要进行单一模态建模即可。

## 3 训练策略及数据

### 3.1 Pretraining - 预训练

**3.1.1 Training Details**

预训练阶段主要进行**模态融合**并且给模型提**供基础的世界知识**（也可以理解为给模型提供**基础的认知能力**）。

一般的预训练做法是将一些其他pre-trained模块冻结，例如LLM和visual encoder。从而仅仅需要去训练一个用于模态融合的interface。这么做的目的是希望在模态融合的过程之中**保证其他模块的预训练知识不流失**。

有些方法也选择去更新pre-trained modules的参数，但这么做的前提是数据质量过硬，否则训练出的大模型容易出现幻觉。

**3.1.2 Data**

预训练数据可以被划分为粗粒度（coarse-grained）和细粒度（fine-grained）。（具体dataset详见论文）

-   粗粒度数据大部分来源于网络，noise过多，可以考虑去用CLIP模型去设立一个阈值过滤掉图文不匹配的数据。
-   细粒度数据大部分需要通过商用模型，例如chatgpt-4o去构建得到数据。

### 3.2 [Instruction-tuning](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=Instruction-tuning&zhida_source=entity)

Instruction-tuning的目的是让模型理解输入的指令从而输出符合指令的答案。通过指令调优，LLM有望去提高zero-shot的能力：依靠模型的泛化能力，在面对训练数据中没有的任务类型时也可以回答正确。

![](https://pic3.zhimg.com/v2-c6080af79c308614f1525146e72620d8_1440w.jpg)

Pretrain-finetune：预训练后微调，微调通常需要大量的任务强相关数据。

Prompting：提示方法减少了对大规模数据的依赖，可以通过提示工程来完成专门的任务。

**Pretrain-finetune和prompting两种模式仅仅可以提升模型的few-shot能力，并不能很好地提升zero-shot能力。**

**Instruction tuning通过指令可以提升模型的泛化能力从而提升zero-shot能力。**

**3.2.1 Training Detail**

![](https://pic4.zhimg.com/v2-a5cb65599dcc97f1d5ba031ceb2b7999_1440w.jpg)

Instruction tuning常见模式

instruction tuning将一条instruction，一组多模态数据作为输入，从而可以得到模型的predicted response（答案），与ground-truth response相比较，通过cross-entropy即可实现模型训练。

3.2.2 **Data Collection**

该文章介绍了三种手机instruction-tuning数据的方法：**data adaptation**, **self-instruction**和 **data mixture**.

3.2.2.1 **Data Adaption**

核心：使用现有数据集去构建指令形式的数据集，通常为简单迁移或者改写。

-   mannual design：人工构建
-   semi-automatic generation aided by GPT：借助商用LLM去生成

3.2.2.2 **Self-Instruction**

> Utilizes LLMs to generate textual instruction-following data using a few hand-annotated samples

基于一些标注好的样本，去让大语言模型生成一部分数据。

（笔者认为self-instruction和data adaption的差别在于，self-instruction可能侧重于生成全新的数据，而data adaption只是在旧数据上进行改写）

**3.2.2.3 Data Mixture**

> Apart from the multimodal instruction data, l**anguage-only user-assistant conversation data** can also be used to improve **conversational proficiencies** and **instruction-following abilities**.

数据混训（带图和不带图），只训练文本信息也可以给MLLM注入知识。

### 3.3 [Alignment tuning](https://zhida.zhihu.com/search?content_id=245067957&content_type=Article&match_order=1&q=Alignment+tuning&zhida_source=entity)

> Alignment tuning is more often used in scenarios where models need to be aligned with specific human preferences,e.g. response with fewer hallucinations.

通过人类的反馈去训练模型。RLHF等强化学习方法...

## 4 Evaluation

_在上学期间，一般读paper时会直接跳过evaluation部分而只看methodology部分。然后真正到了业界之后，才发现评测才是重中之重，模型版本的良好迭代往往需要一个过硬的评测团队..._

一般来说，评测可以分为根据问题的种类分为两类：

-   Closed-set:

-   有固定答案
-   评测集为各类benchmark，例如：ScienceQA，Flickr30K。
-   无需人工干预

-   Open-set:

-   答案较为灵活
-   需要人工打分

## 5 Multimodal Hallucination

> Multimodal hallucination refers to the phenomenon of responses generated by MLLMs being inconsistent with the image content.

MLLM幻觉问题可以理解为：**问题-图片-答案** 三者不匹配的原因。

常见的幻觉问题可以分为三类：

-   **Existence Hallucination**：图片中的物体存在性识别错误。
-   **Attribute Hallucination**：图片中的物体属性识别错误。（例如物体的颜色）
-   **Relationship Hallucination**：图片中的物体之间的关联错误。

## 6 Brainstorming

-   **能力层级递进**：在训练MLLM中，经常发现能力与能力之间是应该有先后学习顺序的，就像不可能在字体都不识别的时候去解出来一道数学题。所以需要Curriculum Learning - 能力循序渐进。因此，如何**鉴别能力之间的层级关系成为了重中之重**。
-   **数据宁缺毋滥**：目前来看，技术上再大的革新数据很脏也建模不好。数据并不是越多越好，脏数据的数量极少也会对MLLM的效果带来毁灭性打击，如果想要一个sota模型，数据清洗与过滤十分重要。
